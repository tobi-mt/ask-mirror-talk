# Railway Service Crash Fix - Complete

## Problems Identified

### Problem 1: Dockerfile Cache Issue ‚ùå
**Build log showed:** Railway was using cached Docker layers from OLD Dockerfile
```
3 RUN apt-get update && apt-get install -y --no-install-recommends ffmpeg libpq5 curl ...
```
‚òùÔ∏è This is the OLD version without PyAV dependencies!

**Expected:**
```
RUN apt-get install -y ffmpeg libavcodec-dev libavformat-dev libavutil-dev libswresample-dev gcc python3-dev ...
```

### Problem 2: Import Error in ingestion service ‚ùå
**Deploy log showed:**
```python
from app.ingestion.pipeline_optimized import main
ImportError: cannot import name 'main' from 'app.ingestion.pipeline_optimized'
```

**Root cause:** `scripts/ingest_all_episodes.py` was trying to import a non-existent `main` function.

## Solutions Applied ‚úÖ

### Solution 1: Bust Docker Cache
Added a comment with date to force Railway to rebuild from that layer:
```dockerfile
# Updated 2026-02-13: Added libavcodec-dev and other FFmpeg libs for PyAV
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        ffmpeg \
        libavcodec-dev \  # These will now be installed
        libavformat-dev \
        ...
```

### Solution 2: Fix Import Error
Completely rewrote `scripts/ingest_all_episodes.py`:

**Before:**
```python
from app.ingestion.pipeline_optimized import main  # ‚ùå Doesn't exist

if __name__ == "__main__":
    main()  # ‚ùå Error!
```

**After:**
```python
from app.core.db import SessionLocal, init_db
from app.ingestion.pipeline_optimized import run_ingestion_optimized  # ‚úÖ Correct

if __name__ == "__main__":
    init_db()
    db = SessionLocal()()
    try:
        result = run_ingestion_optimized(db, max_episodes=None)  # ‚úÖ Works!
        print(f"Processed: {result['processed']} episodes")
    finally:
        db.close()
```

## What Will Happen Now

### Railway Rebuild (in progress)
1. ‚úÖ Detects new commit (877a69f)
2. üîÑ Rebuilds Docker image FROM SCRATCH (cache busted)
3. üîÑ Installs FFmpeg dev libraries: libavcodec-dev, libavformat-dev, etc.
4. üîÑ Installs gcc and python3-dev for building PyAV
5. üîÑ Installs av>=12.0.0 (PyAV module)
6. üîÑ Installs faster-whisper with all dependencies
7. üîÑ Deploys to both services

### Ingestion Service Start
1. ‚úÖ Runs `scripts/ingest_all_episodes.py`
2. ‚úÖ Imports `run_ingestion_optimized` successfully (no more ImportError)
3. ‚úÖ Initializes database
4. ‚úÖ Creates session
5. ‚úÖ Starts ingestion with unlimited episodes
6. ‚úÖ PyAV module available (no more ModuleNotFoundError)

## Verification Steps

### 1. Check Build Log
Look for these NEW lines (not cached):
```
Step X: RUN apt-get install -y ... libavcodec-dev libavformat-dev ...
Step Y: RUN pip install ... av>=12.0.0 faster-whisper==1.0.3 ...
```

Should NOT say "cached" next to the apt-get step.

### 2. Check Deploy Log
Should see:
```
============================================================
INGESTING ALL EPISODES FROM RSS
============================================================
RSS URL: https://anchor.fm/s/261b1464/podcast/rss
Database: postgresql+psycopg://...
Max episodes: UNLIMITED
============================================================
‚úì Database initialized
‚úì Processing episode 1/470: [Episode Title]
  ‚îú‚îÄ Downloaded audio: episode_X.mp3
  ‚îú‚îÄ Transcribing (model=base)...
  ‚îú‚îÄ Processing audio with duration XX:XX
  ‚îú‚îÄ Detected language 'en' with probability 0.99
  ‚îú‚îÄ Transcription complete
  ‚îî‚îÄ ‚úì Episode complete
```

Should NOT see:
```
‚ùå ImportError: cannot import name 'main'
‚ùå ModuleNotFoundError: No module named 'av'
```

### 3. Test PyAV Installation
Once deployed:
```bash
railway run python -c "import av; print('PyAV:', av.__version__)"
```

Expected output:
```
PyAV: 12.x.x
```

### 4. Test Ingestion Manually
```bash
railway run bash
python scripts/bulk_ingest.py --max-episodes 5 --no-confirm
```

Should process 5 episodes successfully.

## Files Changed (Commit 877a69f)

1. ‚úÖ `scripts/ingest_all_episodes.py`
   - Fixed import: `main` ‚Üí `run_ingestion_optimized`
   - Added database initialization
   - Added proper session management
   - Added error handling

2. ‚úÖ `Dockerfile`
   - Added comment with date to bust cache
   - Forces rebuild of apt-get layer
   - Ensures new dependencies are installed

## Timeline

- **14:26 UTC** - Initial PyAV error
- **14:50 UTC** - Fixed Dockerfile (commit 9d8042c)
- **15:15 UTC** - Discovered Railway using cached layers
- **15:20 UTC** - Fixed import error + busted cache (commit 877a69f)
- **15:22 UTC** - Pushed to Bitbucket ‚úÖ
- **~15:35 UTC** - Railway rebuild should complete
- **After deployment** - Services should be healthy

## Success Criteria

### Build Success ‚úÖ
- [ ] Railway build shows NEW apt-get command (not cached)
- [ ] FFmpeg dev libraries installed
- [ ] PyAV module installed
- [ ] faster-whisper installed with dependencies
- [ ] Build completes without errors

### Deploy Success ‚úÖ
- [ ] Healthcheck passes (service responds on /health)
- [ ] No ImportError in logs
- [ ] No ModuleNotFoundError in logs
- [ ] Ingestion starts processing episodes
- [ ] Episodes successfully transcribed

### Runtime Success ‚úÖ
- [ ] `import av` works
- [ ] `ffmpeg -version` works
- [ ] Transcription completes without errors
- [ ] Episodes saved to database
- [ ] API returns results with new episodes

## Why Previous Attempts Failed

### Attempt 1: Created nixpacks.toml ‚ùå
- Railway uses Dockerfile (specified in railway.toml)
- Nixpacks config was ignored

### Attempt 2: Updated Dockerfile ‚ùå
- Changes were correct
- But Railway used cached layers
- Never actually installed the new dependencies

### Attempt 3: Fixed imports BUT service still crashed ‚ùå
- Import error prevented service from starting
- Even though Dockerfile was correct, service never got far enough to test it

## Current Attempt: Fixed BOTH Issues ‚úÖ

1. ‚úÖ Busted Docker cache ‚Üí Forces new build with PyAV dependencies
2. ‚úÖ Fixed import error ‚Üí Service can now start successfully
3. ‚úÖ Combined fix ‚Üí Service starts AND transcription works

## Next Steps After Deployment

### 1. Verify Everything Works
```bash
# Test imports
railway run python -c "import av, faster_whisper; print('All good!')"

# Test ingestion with 5 episodes
railway run bash
python scripts/bulk_ingest.py --max-episodes 5 --no-confirm
```

### 2. Run Full Ingestion
```bash
# Process in batches
python scripts/bulk_ingest.py --max-episodes 50 --no-confirm
# Wait for completion, then repeat
python scripts/bulk_ingest.py --max-episodes 50 --no-confirm
# Continue until all 467 episodes loaded
```

### 3. Test API
```bash
curl -X POST "https://your-app.railway.app/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is Mirror Talk about?"}'
```

Should return answers from ingested episodes.

## Monitoring

Watch Railway logs in real-time:
```bash
# Ingestion service
railway logs --service mirror-talk-ingestion -f

# API service  
railway logs --service mirror-talk-api -f
```

Check deployment status:
- Railway Dashboard ‚Üí Services ‚Üí Check for "‚úÖ Deployed"
- Healthcheck should show "Healthy"

## If It Still Fails

### Check Build Log
If apt-get still shows "cached":
1. Go to Railway Dashboard
2. Service Settings ‚Üí "Redeploy"
3. Check "Force Rebuild"
4. Deploy

### Check Deploy Log
If still seeing ImportError:
1. Verify commit 877a69f was actually deployed
2. Check Railway is deploying from correct branch (main)
3. Manually trigger redeploy

### Contact Support
With:
- Build log showing cache status
- Deploy log showing exact error
- Git commit hash deployed

---

**Status:** üîÑ Fix deployed, waiting for Railway rebuild  
**Commits:** 9d8042c (Dockerfile fix), 877a69f (import fix + cache bust)  
**ETA:** 10-15 minutes for rebuild and deploy  
**Expected Result:** Service starts, transcription works, ingestion succeeds  
